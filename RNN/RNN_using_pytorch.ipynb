{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AbdDBOAVKR3y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data  = \"Implement RNN using Pytorch\"\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "char_to_ix = {ch: i for i,ch in enumerate(chars)}\n",
        "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "input_indices = [char_to_ix[ch] for ch in data[:-1]]\n",
        "target_indices = [char_to_ix[ch] for ch in data[1:]]\n"
      ],
      "metadata": {
        "id": "4twIQNjAKfMk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PytorchRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super(PytorchRNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    #input_size is vocab_size (one-hot encoding)\n",
        "    self.rnn = nn.RNN(input_size,hidden_size,num_layers=1,batch_first = True)\n",
        "\n",
        "    #Output layer (maps hidden state to vocab space)\n",
        "    self.fc = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self,input_tensor,hidden_state):\n",
        "    rnn_out , hidden_state_out = self.rnn(input_tensor,hidden_state)\n",
        "\n",
        "    output = self.fc(rnn_out)\n",
        "\n",
        "    return output,hidden_state_out\n"
      ],
      "metadata": {
        "id": "v495y5u6K3mY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 100\n",
        "model = PytorchRNN(vocab_size,hidden_size,vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
        "\n",
        "X = torch.zeros(1,len(input_indices),vocab_size)\n",
        "for t,idx in enumerate(input_indices):\n",
        "  X[0,t,idx] = 1.0\n",
        "Y = torch.LongTensor(target_indices).unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "YdcZ_woEL5cB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  h0 = torch.zeros(1,1,hidden_size)\n",
        "  optimizer.zero_grad()\n",
        "  output,h_final = model(X,h0)\n",
        "\n",
        "  loss = criterion(output.view(-1,vocab_size),Y.view(-1))\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(f\"Iter {i} , Loss: {loss.item():.4f}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwClMbGfMWnu",
        "outputId": "aa3db796-245c-4a57-9ab3-295631c5edcf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0 , Loss: 2.9893\n",
            "Iter 100 , Loss: 0.0004\n",
            "Iter 200 , Loss: 0.0002\n",
            "Iter 300 , Loss: 0.0002\n",
            "Iter 400 , Loss: 0.0001\n",
            "Iter 500 , Loss: 0.0001\n",
            "Iter 600 , Loss: 0.0001\n",
            "Iter 700 , Loss: 0.0001\n",
            "Iter 800 , Loss: 0.0000\n",
            "Iter 900 , Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_pytorch(model,start_char,num_chars):\n",
        "  model.eval()\n",
        "  h = torch.zeros(1,1,model.hidden_size)\n",
        "\n",
        "  input_idx = char_to_ix[start_char]\n",
        "  input_one_hot = torch.zeros(1,1,vocab_size)\n",
        "  input_one_hot[0,0,input_idx] = 1.0\n",
        "\n",
        "  text = start_char\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for t in range(num_chars):\n",
        "      output, h = model(input_one_hot,h)\n",
        "\n",
        "      p = torch.softmax(output.squeeze(0).squeeze(0), dim = 0)\n",
        "\n",
        "      ix = torch.multinomial(p,1).item()\n",
        "\n",
        "      text += ix_to_char[ix]\n",
        "\n",
        "      input_one_hot.zero_()\n",
        "      input_one_hot[0,0,ix]  = 1.0\n",
        "\n",
        "  return text\n",
        "\n",
        "print(f\"Start char: {data[0]}\")\n",
        "print(f\"Generated text : {sample_pytorch(model,data[0],len(data) -1 )}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCOpcPXaNFUT",
        "outputId": "2612f873-2a43-4161-9ed9-ac8086d6dd81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start char: I\n",
            "Generated text : Implement RNN using Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UF2xzQV8N1Br"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}